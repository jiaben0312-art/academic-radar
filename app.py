# ==========================================
# 0. ä¸Šå¸æ¨¡å¼è¡¥ä¸ï¼šæ‹¯æ•‘ Python 3.14 çš„å…¨å±€ä¾èµ–
# ==========================================
import sys
import builtins
builtins.sys = sys 

import streamlit as st
import requests
import pandas as pd
import plotly.graph_objects as go
import time
import re

# ==========================================
# 1. ç½‘é¡µå…¨å±€é…ç½®
# ==========================================
st.set_page_config(page_title="å…¨çƒå­¦æœ¯å‰æ²¿é›·è¾¾", page_icon="ğŸ“¡", layout="wide")
st.title("ğŸ“¡ å…¨çƒå­¦æœ¯å‰æ²¿æ–‡çŒ®é›·è¾¾ (å…¨å­¦ç§‘æµ·é‡ IF ç‰ˆ)")
st.markdown("å†…ç½®æ‰©å®¹ç‰ˆ IF æ•°æ®åº“ï¼ˆæ¶µç›–åŒ»å­¦ä¸“åˆŠã€ç»¼åˆå¼€æºå¤§åˆŠç­‰ï¼‰ã€‚è‡ªåŠ¨æŠ“å–æœ€æ–°æ–‡çŒ®å¹¶ç”Ÿæˆå›¾è¡¨ã€‚")

# ==========================================
# 2. ä¾§è¾¹æ 
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ æ£€ç´¢å‚æ•°è®¾ç½®")
    search_keyword = st.text_input("ğŸ” æ£€ç´¢å…³é”®è¯ (æ”¯æŒæ¨¡ç³Šæœç´¢)", value="glaucoma")
    start_date = st.date_input("ğŸ“… èµ·å§‹æ—¥æœŸ", value=pd.to_datetime("2025-01-01"))
    max_papers = st.slider("ğŸ“‘ æœ€å¤§æŠ“å–æ•°é‡", min_value=50, max_value=500, value=200, step=50)
    st.markdown("---")
    st.markdown("ğŸ’¡ **æç¤º**: ä¼šè®®è®ºæ–‡åŠé¢„å°æœ¬(å¦‚ Zenodo, OSF Preprints)æœ¬èº«æ—  IF åˆ†æ•°ã€‚")

def contains_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

if contains_chinese(search_keyword):
    st.warning("ğŸ‘€ **æ£€æµ‹åˆ°ä¸­æ–‡ï¼** å»ºè®®æ›¿æ¢ä¸º**è‹±æ–‡å…³é”®è¯**ä»¥è·å–æœ€ç²¾å‡†çš„æ–‡çŒ®ï¼")

# ==========================================
# 3. å²è¯—çº§å…¨å­¦ç§‘å½±å“å› å­å¤§å­—å…¸ (è¶…çº§æ‰©å®¹ç‰ˆ)
# ==========================================
SUPER_IF_DICT = {
    # --- ç»¼åˆ / é¡¶åˆŠ ---
    "Nature": 64.8, "Science": 56.9, "Cell": 64.5, "Nature Communications": 16.6, 
    "Science Advances": 13.6, "Proceedings of the National Academy of Sciences": 11.1,
    
    # --- ç”Ÿç‰©åŒ»å­¦é¡¶åˆŠ ---
    "The New England Journal of Medicine": 158.5, "The Lancet": 168.9, "JAMA": 120.7, 
    "BMJ": 105.7, "Nature Medicine": 82.9, "Nature Biotechnology": 68.1,
    "Nature Genetics": 30.8, "Immunity": 32.4, "Cancer Cell": 38.5, "Lancet Oncology": 51.1,
    
    # --- çœ¼ç§‘ / è§†è§‰ç§‘å­¦ä¸“åˆŠ (Ophthalmology) ---
    "Ophthalmology": 13.1, "JAMA Ophthalmology": 7.8, "Progress in Retinal and Eye Research": 17.8,
    "American Journal of Ophthalmology": 4.1, "British Journal of Ophthalmology": 4.6,
    "Investigative Ophthalmology & Visual Science": 4.9, "Acta Ophthalmologica": 3.4,
    "Eye": 3.9, "Current Eye Research": 2.0, "Experimental Eye Research": 3.0,
    "International Ophthalmology": 1.4, "Translational Vision Science & Technology": 3.0,
    "Current Ophthalmology Reports": 1.2, "BMC Ophthalmology": 2.0,
    "Journal of Glaucoma": 2.0, "Clinical Ophthalmology": 1.7,
    
    # --- æé«˜é¢‘å¼€æºâ€œè¶…çº§å¤§åˆŠâ€ (Frontiers, MDPI, BMC, PLoS) ---
    "PLoS One": 3.7, "Scientific Reports": 4.6, 
    "Frontiers in Cell and Developmental Biology": 5.3, "Frontiers in Immunology": 7.3,
    "Frontiers in Medicine": 3.9, "Frontiers in Oncology": 4.7, "Frontiers in Pharmacology": 5.6,
    "Frontiers in Neuroscience": 4.3, "Frontiers in Plant Science": 5.6,
    "International Journal of Molecular Sciences": 5.6, "Cancers": 5.2, "Cells": 6.0,
    "Sensors": 3.9, "Molecules": 4.6, "Marine Drugs": 5.4, "Nutrients": 5.9,
    "Journal of Clinical Medicine": 3.9, "Antioxidants": 7.0,
    "BMC Public Health": 4.1, "BMC Medicine": 9.3, "BMC Cancer": 3.8,
    
    # --- è®¡ç®—æœº / AI / ä¿¡æ¯ç§‘å­¦ ---
    "Nature Machine Intelligence": 25.8, "IEEE Transactions on Pattern Analysis and Machine Intelligence": 23.6,
    "International Journal of Computer Vision": 19.5, "Information Fusion": 18.6,
    "IEEE Transactions on Neural Networks and Learning Systems": 14.4, "Artificial Intelligence": 14.4,
    "Medical Image Analysis": 13.8, "IEEE Transactions on Image Processing": 10.6,
    "Expert Systems with Applications": 8.5, "Pattern Recognition": 8.0, "Knowledge-Based Systems": 8.8,
    
    # --- åŒ–å­¦ / ææ–™ / ç¯å¢ƒ ---
    "Chemical Society Reviews": 46.2, "Advanced Materials": 29.4, "Journal of the American Chemical Society": 15.0, 
    "Energy & Environmental Science": 32.4, "Applied Catalysis B: Environment and Energy": 22.1, 
    "Chemical Engineering Journal": 15.1, "Water Research": 12.8, "Journal of Cleaner Production": 11.1, 
    "Science of The Total Environment": 9.8, "ACS Nano": 17.1, "Nano Letters": 10.8, "Small": 13.3
}
super_if_dict_lower = {k.lower(): v for k, v in SUPER_IF_DICT.items()}

# ==========================================
# 4. æ ¸å¿ƒæŠ“å–å‡½æ•°
# ==========================================
@st.cache_data(show_spinner=False)
def fetch_and_process_papers(keyword, date_str, limit):
    url = "https://api.openalex.org/works"
    papers_data = []
    page = 1
    
    while len(papers_data) < limit:
        params = {
            "search": keyword,
            "filter": f"from_publication_date:{date_str}",
            "sort": "publication_date:desc",
            "per-page": 100,
            "page": page
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code != 200: break
        except Exception:
            break
            
        data = response.json()
        results = data.get("results", [])
        if not results: break
            
        for item in results:
            source = item.get("primary_location", {}).get("source")
            journal = source.get("display_name", "Unknown") if source else "Unknown"
            
            concepts = item.get("concepts", [])
            sub_field = "Others"
            for c in concepts:
                if c.get("level", 0) > 0: 
                    sub_field = c.get("display_name", "Others")
                    break
            
            papers_data.append({
                "å‘è¡¨æ—¥æœŸ": item.get("publication_date", ""),
                "æ ‡é¢˜": item.get("title", "No Title"),
                "æœŸåˆŠå": journal,
                "é¢†åŸŸèšç±»": sub_field,
                "DOI": item.get("doi", "")
            })
            if len(papers_data) >= limit: break
            
        page += 1
        time.sleep(0.1) 
        
    df = pd.DataFrame(papers_data)
    if not df.empty:
        # éƒ¨åˆ†åŒ…å«åŒ¹é…é€»è¾‘ï¼šåº”å¯¹å¸¦æœ‰åç¼€çš„æœŸåˆŠå
        def match_if(journal_name):
            j_lower = str(journal_name).lower()
            # 1. å°è¯•å®Œå…¨åŒ¹é…
            if j_lower in super_if_dict_lower:
                return super_if_dict_lower[j_lower]
            # 2. å°è¯•å­ä¸²åŒ¹é… (é’ˆå¯¹åå­—å¸¦å°å°¾å·´çš„æƒ…å†µ)
            for key, val in super_if_dict_lower.items():
                if key in j_lower:
                    return val
            return None
            
        df['IF'] = df['æœŸåˆŠå'].apply(match_if)
    return df

# ==========================================
# 5. ä¸»ç¨‹åºæ¸²æŸ“
# ==========================================
if st.sidebar.button("ğŸš€ å¼€å§‹æ£€ç´¢å¹¶ç”Ÿæˆå›¾è¡¨", type="primary", use_container_width=True):
    
    with st.spinner(f"æ­£åœ¨è·¨åº“æ¨¡ç³Šæ£€ç´¢å…³äº '{search_keyword}' çš„æ–‡çŒ®..."):
        df = fetch_and_process_papers(search_keyword, start_date.strftime("%Y-%m-%d"), max_papers)
    
    if df.empty:
        st.error("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡çŒ®ã€‚")
    else:
        st.success(f"ğŸ‰ æŠ“å–æˆåŠŸï¼å…±è·å– {len(df)} ç¯‡æ–‡çŒ®ã€‚")
        
        df_with_if = df.dropna(subset=['IF']).copy()
        match_rate = len(df_with_if) / len(df) * 100 if len(df) > 0 else 0
        
        col1, col2, col3 = st.columns(3)
        col1.metric("æŠ“å–æ€»æ–‡çŒ®æ•°", f"{len(df)} ç¯‡")
        col2.metric("æˆåŠŸåŒ¹é… IF æ•°é‡", f"{len(df_with_if)} ç¯‡")
        col3.metric("IF åŒ¹é…ç‡", f"{match_rate:.1f}%")

        if not df_with_if.empty:
            st.subheader("ğŸ“Š ç»†åˆ†é¢†åŸŸå½±å“å› å­åˆ†å¸ƒ")
            
            fig = go.Figure()
            unique_fields = df_with_if['é¢†åŸŸèšç±»'].unique()
            
            for field in unique_fields:
                df_sub = df_with_if[df_with_if['é¢†åŸŸèšç±»'] == field]
                hover_text = (
                    "<b>å½±å“å› å­:</b> " + df_sub['IF'].astype(str) + "<br>" +
                    "<b>æ ‡é¢˜:</b> " + df_sub['æ ‡é¢˜'].str[:80] + "...<br>" +
                    "<b>æœŸåˆŠ:</b> " + df_sub['æœŸåˆŠå'] + "<br>" +
                    "<b>DOI:</b> " + df_sub['DOI']
                )
                
                fig.add_trace(go.Box(
                    y=df_sub['IF'], x=df_sub['é¢†åŸŸèšç±»'], name=field,
                    boxpoints='all', jitter=0.5, whiskerwidth=0.2, marker_size=5,
                    text=hover_text, hoverinfo='text'
                ))
                
            fig.update_layout(
                xaxis_tickangle=-35, showlegend=False, height=600,
                plot_bgcolor='rgba(245,245,245,1)', yaxis_title="å½±å“å› å­ (IF)"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("âš ï¸ æœªèƒ½åŒ¹é…åˆ°å½±å“å› å­ã€‚æ‚¨å¯ä»¥æŸ¥é˜…ä¸‹æ–¹å®Œæ•´åˆ—è¡¨ã€‚")

        st.subheader("ğŸ“‹ è¯¦ç»†æ–‡çŒ®æ•°æ®")
        df_display = df.copy()
        df_display['IF'] = df_display['IF'].fillna("æœªåŒ¹é…/ä¼šè®®/é¢„å°æœ¬")
        st.dataframe(df_display[['å‘è¡¨æ—¥æœŸ', 'é¢†åŸŸèšç±»', 'IF', 'æœŸåˆŠå', 'æ ‡é¢˜', 'DOI']], use_container_width=True, hide_index=True)